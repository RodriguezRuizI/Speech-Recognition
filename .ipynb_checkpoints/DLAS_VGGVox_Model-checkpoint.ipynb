{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STu7KzUhNGyY"
   },
   "source": [
    "# VGGVox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uiO0nyYlDP6a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 737
    },
    "id": "YG_pElNJDP6d",
    "outputId": "ebcea0dc-824d-42a4-b26b-078dd1ee9d52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/isabel.rodriguez/opt/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.20.3)\n",
      "Requirement already satisfied: scipy in /Users/isabel.rodriguez/opt/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.7.1)\n",
      "Requirement already satisfied: pandas in /Users/isabel.rodriguez/opt/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (1.3.4)\n",
      "Requirement already satisfied: torch in /Users/isabel.rodriguez/opt/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (1.11.0)\n",
      "Requirement already satisfied: torchvision in /Users/isabel.rodriguez/opt/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (0.12.0)\n",
      "Requirement already satisfied: matplotlib in /Users/isabel.rodriguez/opt/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (3.4.3)\n",
      "Requirement already satisfied: tqdm in /Users/isabel.rodriguez/opt/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (4.62.3)\n",
      "Collecting argparse\n",
      "  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: torchsummary in /Users/isabel.rodriguez/opt/anaconda3/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (1.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/isabel.rodriguez/opt/anaconda3/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/isabel.rodriguez/opt/anaconda3/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 3)) (2021.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/isabel.rodriguez/opt/anaconda3/lib/python3.9/site-packages (from torch->-r requirements.txt (line 4)) (3.10.0.2)\n",
      "Requirement already satisfied: requests in /Users/isabel.rodriguez/opt/anaconda3/lib/python3.9/site-packages (from torchvision->-r requirements.txt (line 5)) (2.26.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/isabel.rodriguez/opt/anaconda3/lib/python3.9/site-packages (from torchvision->-r requirements.txt (line 5)) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/isabel.rodriguez/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 6)) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/isabel.rodriguez/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/isabel.rodriguez/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 6)) (3.0.4)\n",
      "Requirement already satisfied: six in /Users/isabel.rodriguez/opt/anaconda3/lib/python3.9/site-packages (from cycler>=0.10->matplotlib->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/isabel.rodriguez/opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision->-r requirements.txt (line 5)) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/isabel.rodriguez/opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision->-r requirements.txt (line 5)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/isabel.rodriguez/opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision->-r requirements.txt (line 5)) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/isabel.rodriguez/opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision->-r requirements.txt (line 5)) (1.26.7)\n",
      "Installing collected packages: argparse\n",
      "Successfully installed argparse-1.4.0\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('VGGVox-PyTorch'):\n",
    "    ! git clone https://github.com/Derpimort/VGGVox-PyTorch.git\n",
    "    if not os.path.exists('VGGVox-PyTorch/dataset'):\n",
    "        os.system('mkdir dataset')\n",
    "    os.system('rm -r VGGVox-PyTorch/data')\n",
    "    os.system('cp -r dataset/ VGGVox-PyTorch/dataset/' )\n",
    "    os.chdir('VGGVox-PyTorch')\n",
    "    ! pip install -r requirements.txt\n",
    "    \n",
    "else:\n",
    "    if not os.path.exists('VGGVox-PyTorch/dataset'):\n",
    "        os.system('mkdir dataset')\n",
    "    os.system(' cp -r dataset/ VGGVox-PyTorch/dataset/' )\n",
    "    os.chdir('VGGVox-PyTorch')\n",
    "    ! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AVY74FF7DP6h"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Subset, Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from vggm import VGGM\n",
    "import argparse\n",
    "from train import AudioDataset, accuracy, ppdf, LOCAL_DATA_DIR, MODEL_DIR\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "T2W84SkUDP6j"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=VGGM(1251)\n",
    "model.load_state_dict(torch.load(MODEL_DIR+\"VGGM300_BEST_140_81.99.pth\", map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "### This is to extract an activation from one layer ...\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rbpyjszNDP6l"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/Users/isabel.rodriguez/Desktop/Isa/MUIT - Machine Learning/DLAS/project/VGGVox-PyTorch'\n",
    "\n",
    "df = pd.read_csv('./dataset/labels.csv')\n",
    "\n",
    "Datasets={\"test\":AudioDataset(df, DATA_DIR, is_train=False)}\n",
    "\n",
    "Dataloaders={i:DataLoader(Datasets[i], batch_size=1, shuffle=False, num_workers=2) for i in Datasets}\n",
    "\n",
    "embedding_arr = []\n",
    "\n",
    "for audio, labels in Dataloaders['test']:\n",
    "        audio = audio.to(device)\n",
    "        labels = labels.to(device)\n",
    "        model.classifier.fc7.register_forward_hook(get_activation('fc7'))\n",
    "        outputs = model(audio)\n",
    "\n",
    "        embedding_arr.append(activation['fc7'].cpu().numpy().reshape(-1))\n",
    "\n",
    "df['Embeddings'] = pd.Series(embedding_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "5uuVp4TrDP6n",
    "outputId": "1f7f1ece-1a55-453c-e43a-aca6d82cbd76"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMveE3h-DP6o"
   },
   "source": [
    "## Take first embedding of classes 0 and 1 as reference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RpzPXShUDP6q",
    "outputId": "4f83e0c4-b27b-44be-866f-b18c73b445be"
   },
   "outputs": [],
   "source": [
    "df[\"Pred_Label\"] = 0\n",
    "\n",
    "speaker_t1 = 0\n",
    "speaker_t2 = 1\n",
    "embedding_1 = df[df['Label']== speaker_t1].iloc[0]['Embeddings']\n",
    "embedding_2 = df[df['Label']== speaker_t2].iloc[0]['Embeddings']\n",
    "\n",
    "similarity = cosine_similarity(embedding_1.reshape(1,-1), embedding_2.reshape(1,-1))\n",
    "cosine_distance = 1 - similarity\n",
    "\n",
    "print('Cosine similarity: ', similarity, ' cosine distance: ', cosine_distance)\n",
    "\n",
    "\n",
    "print('\\n\\n-----------------Speaker: ', speaker_t1)\n",
    "print(df[df['Label']== speaker_t1].iloc[0],'\\n')\n",
    "\n",
    "\n",
    "print('-----------------Speaker: ', speaker_t2)\n",
    "print(df[df['Label']== speaker_t2].iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2s736flzDP6s",
    "outputId": "5c042437-8540-4714-c6cc-a8a46decd7b6"
   },
   "outputs": [],
   "source": [
    "for i in range (0, len(df['Embeddings'])):\n",
    "    if i!=0 and i !=50:\n",
    "        similarity_sp1 = cosine_similarity(embedding_1.reshape(1,-1), df['Embeddings'][i].reshape(1,-1))\n",
    "        cosine_distance_sp1 = 1 - similarity_sp1\n",
    "        similarity_sp2 = cosine_similarity(embedding_2.reshape(1,-1), df['Embeddings'][i].reshape(1,-1))\n",
    "        cosine_distance_sp2 = 1 - similarity_sp2\n",
    "\n",
    "        print('Cosine similarity with speaker 1: ', similarity_sp1, ' cosine distance with speaker 1: ', cosine_distance_sp1)\n",
    "        print('Cosine similarity with speaker 2: ', similarity_sp2, ' cosine distance with speaker 2: ', cosine_distance_sp2)\n",
    "        \n",
    "        if min(cosine_distance_sp1,cosine_distance_sp2) == cosine_distance_sp1:\n",
    "            df['Pred_Label'][i] = 0\n",
    "        elif min(cosine_distance_sp1,cosine_distance_sp2) == cosine_distance_sp2:\n",
    "            df['Pred_Label'][i] = 1\n",
    "        else:\n",
    "            df['Pred_Label'][i] = np.nan\n",
    "    else:\n",
    "        df['Pred_Label'].iloc[0] = 0\n",
    "        df['Pred_Label'].iloc[50] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "#\n",
    "conf_matrix = confusion_matrix(y_true=df['Label'], y_pred=df['Pred_Label'])\n",
    "#\n",
    "# Print the confusion matrix using Matplotlib\n",
    "#\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_results = {'tn': conf_matrix[0, 0], 'fp': conf_matrix[0, 1], 'fn': conf_matrix[1, 0], 'tp': conf_matrix[1, 1]}\n",
    "\n",
    "test_acc = (cm_results['tp']+cm_results['tn'])/(cm_results['tp']+cm_results['fp']+cm_results['tn']+cm_results['fn'])\n",
    "test_precision = cm_results['tp']/(cm_results['tp']+cm_results['fp'])\n",
    "test_recall = cm_results['tp']/(cm_results['tp']+cm_results['fn'])\n",
    "test_F1_Score = (2* test_precision * test_recall)/ (test_precision + test_recall)\n",
    "\n",
    "print(\"Test accuracy: {}\".format(test_acc))\n",
    "print(\"Test precision: {}\".format(test_precision))\n",
    "print(\"Test recall: {}\".format(test_recall))\n",
    "print(\"Test f1 score: {}\".format(test_F1_Score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 100 #maximum number of components\n",
    "\n",
    "X = np.stack(df['Embeddings'].values)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "pca = PCA(n_components = n_components)\n",
    "\n",
    "pca.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = df['Label']\n",
    "cdict = {0: 'red', 1: 'blue'}\n",
    "\n",
    "Z1 = pca.transform(X_scaled)[:,0]\n",
    "Z2 = pca.transform(X_scaled)[:,1]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for g in np.unique(group):\n",
    "    ix = np.where(group == g)\n",
    "    ax.scatter(Z1[ix], Z2[ix], c = cdict[g], label = g, s = 50)\n",
    "\n",
    "plt.xlabel(\"First Principal Component\",fontsize=14)\n",
    "plt.ylabel(\"Second Principal Component\",fontsize=14)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "X_tsne = TSNE(random_state=123).fit_transform(X_scaled)\n",
    "\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tsne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = []\n",
    "for label in df['Label']:\n",
    "    if label == 0:\n",
    "        color.append('red')\n",
    "    elif label == 1:\n",
    "        color.append('blue')\n",
    "\n",
    "plt.scatter(X_tsne[:,0] ,X_tsne[:,1], c = color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuyHuOiyDP6u"
   },
   "source": [
    "## Take the mean of the 10 first embeddings of classes 0 and 1 as reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AuXhUcUXDP6w",
    "outputId": "e604c01b-679f-44e8-c31a-2c29c2fa1a81"
   },
   "outputs": [],
   "source": [
    "df[\"Pred_Label\"] = 0\n",
    "\n",
    "speaker_t1 = 0\n",
    "speaker_t2 = 1\n",
    "embedding_1 = df[df['Label']== speaker_t1].iloc[:10]['Embeddings'].mean()\n",
    "embedding_2 = df[df['Label']== speaker_t2].iloc[:10]['Embeddings'].mean()\n",
    "\n",
    "\n",
    "similarity = cosine_similarity(embedding_1.reshape(1,-1), embedding_2.reshape(1,-1))\n",
    "cosine_distance = 1 - similarity\n",
    "\n",
    "print('Cosine similarity: ', similarity, ' cosine distance: ', cosine_distance)\n",
    "\n",
    "\n",
    "print('\\n\\n-----------------Speaker: ', speaker_t1)\n",
    "print(df[df['Label']== speaker_t1].iloc[0],'\\n')\n",
    "\n",
    "\n",
    "print('-----------------Speaker: ', speaker_t2)\n",
    "print(df[df['Label']== speaker_t2].iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHSqUDpcDP6x",
    "outputId": "a9b40646-5d7d-4ee3-816e-a66565bf103f"
   },
   "outputs": [],
   "source": [
    "for i in range (0, len(df['Embeddings'])):\n",
    "    \n",
    "    similarity_sp1 = cosine_similarity(embedding_1.reshape(1,-1), df['Embeddings'][i].reshape(1,-1))\n",
    "    cosine_distance_sp1 = 1 - similarity_sp1\n",
    "    similarity_sp2 = cosine_similarity(embedding_2.reshape(1,-1), df['Embeddings'][i].reshape(1,-1))\n",
    "    cosine_distance_sp2 = 1 - similarity_sp2\n",
    "\n",
    "    print('Cosine similarity with speaker 1: ', similarity_sp1, ' cosine distance with speaker 1: ', cosine_distance_sp1)\n",
    "    print('Cosine similarity with speaker 2: ', similarity_sp2, ' cosine distance with speaker 2: ', cosine_distance_sp2)\n",
    "        \n",
    "    if min(cosine_distance_sp1,cosine_distance_sp2) == cosine_distance_sp1:\n",
    "        df['Pred_Label'][i] = 0\n",
    "    elif min(cosine_distance_sp1,cosine_distance_sp2) == cosine_distance_sp2:\n",
    "        df['Pred_Label'][i] = 1\n",
    "    else:\n",
    "        df['Pred_Label'][i] = np.nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "UQxDXY1YDP6y",
    "outputId": "347dc8b4-bb4f-4ac9-a6af-1803b73f171c"
   },
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "#\n",
    "conf_matrix = confusion_matrix(y_true=df['Label'], y_pred=df['Pred_Label'])\n",
    "#\n",
    "# Print the confusion matrix using Matplotlib\n",
    "#\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "i1MkjbbsDP6z",
    "outputId": "2e0ddddf-0f10-4923-daa5-bd8409bdd1e7"
   },
   "outputs": [],
   "source": [
    "cm_results = {'tn': conf_matrix[0, 0], 'fp': conf_matrix[0, 1], 'fn': conf_matrix[1, 0], 'tp': conf_matrix[1, 1]}\n",
    "\n",
    "test_acc = (cm_results['tp']+cm_results['tn'])/(cm_results['tp']+cm_results['fp']+cm_results['tn']+cm_results['fn'])\n",
    "test_precision = cm_results['tp']/(cm_results['tp']+cm_results['fp'])\n",
    "test_recall = cm_results['tp']/(cm_results['tp']+cm_results['fn'])\n",
    "test_F1_Score = (2* test_precision * test_recall)/ (test_precision + test_recall)\n",
    "\n",
    "print(\"Test accuracy: {}\".format(test_acc))\n",
    "print(\"Test precision: {}\".format(test_precision))\n",
    "print(\"Test recall: {}\".format(test_recall))\n",
    "print(\"Test f1 score: {}\".format(test_F1_Score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ThQsnI9oJIG3",
    "outputId": "29745373-acb1-4202-d85f-085ab0ae8f29"
   },
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DM5-YxrVDP6z",
    "outputId": "c50dc7ec-67d8-4322-f940-21f679743023"
   },
   "outputs": [],
   "source": [
    "n_components = 100 #maximum number of components\n",
    "\n",
    "X = np.stack(df['Embeddings'].values)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "pca = PCA(n_components = n_components)\n",
    "\n",
    "pca.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "9cy7GyBkDP60",
    "outputId": "fc44a37c-8f75-4bf9-9b1c-57a283eb4d62"
   },
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "U6Lty7jSDP61",
    "outputId": "111167ac-c1b4-4d9d-fca0-4a37a187d673"
   },
   "outputs": [],
   "source": [
    "group = df['Label']\n",
    "cdict = {0: 'red', 1: 'blue'}\n",
    "\n",
    "Z1 = pca.transform(X_scaled)[:,0]\n",
    "Z2 = pca.transform(X_scaled)[:,1]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for g in np.unique(group):\n",
    "    ix = np.where(group == g)\n",
    "    ax.scatter(Z1[ix], Z2[ix], c = cdict[g], label = g, s = 50)\n",
    "\n",
    "plt.xlabel(\"First Principal Component\",fontsize=14)\n",
    "plt.ylabel(\"Second Principal Component\",fontsize=14)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wr7o5bXrDP63",
    "outputId": "8eb5cc3b-914b-4479-afc0-8c585dd50333"
   },
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "X_tsne = TSNE(random_state=123).fit_transform(X_scaled)\n",
    "\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6rXlBm0DDP64",
    "outputId": "2b8b7429-d868-46d1-b755-f33a99893db2"
   },
   "outputs": [],
   "source": [
    "X_tsne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "96dtq0tyDP65",
    "outputId": "d13c53e0-6712-49a0-c52e-5883c0857394"
   },
   "outputs": [],
   "source": [
    "color = []\n",
    "for label in df['Label']:\n",
    "    if label == 0:\n",
    "        color.append('red')\n",
    "    elif label == 1:\n",
    "        color.append('blue')\n",
    "\n",
    "plt.scatter(X_tsne[:,0] ,X_tsne[:,1], c = color)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DLAS_VGGVox_Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
